{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Sign Recognition with CNN\n",
    "\n",
    "Using a Convolutional Neural Network for recognizing hand signs.\n",
    "\n",
    "_PyTorch implementation of the assignment of Course 4 of Coursera's Deep Learning Specialization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will create a custom dataset that can load the images from the given `.h5` files. The files contain:\n",
    "\n",
    "- 1080 training examples\n",
    "- 120 testing examples\n",
    "- each image is of size: (64, 64, 3)\n",
    "- there are 6 different signs (numbers 0 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandSignsDataset(Dataset):\n",
    "    def __init__(self, train, transform=None):\n",
    "        prefix = 'train' if train else 'test'\n",
    "        dataset = h5py.File(f'data/{prefix}_signs.h5', 'r')\n",
    "\n",
    "        self.X = np.array(dataset[f'{prefix}_set_x'][:])\n",
    "        self.y = np.array(dataset[f'{prefix}_set_y'][:])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X = self.transform(self.X[idx, :]) if self.transform else self.X[idx, :]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create training and test sets. We use `ToTensor()` to convert the images to a PyTorch tensor with shape channels x height x width, and with pixel values rescaled from [0, 255] to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = DataLoader(HandSignsDataset(train=True, transform=transforms.ToTensor()), batch_size=64, shuffle=True, num_workers=4)\n",
    "testing = DataLoader(HandSignsDataset(train=False, transform=transforms.ToTensor()), batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(training))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis('off')\n",
    "plt.title('Training Images')\n",
    "# We need to swap the axes to (height, width, channels) for matplotlib to plot the image correctly\n",
    "plt.imshow(np.transpose(vutils.make_grid(batch[0], padding=2, normalize=True), (1, 2, 0)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use a Convolutional Neural Network as follows:\n",
    "\n",
    "- Hidden Layer 1: Conv -> ReLU\n",
    "  - in_channels=3 (RBG)\n",
    "  - filters=8\n",
    "  - filter_size=4\n",
    "  - stride=1\n",
    "  - padding=same\n",
    "- Hidden Layer 2: MaxPool\n",
    "  - filter_size=8\n",
    "  - stride=8\n",
    "  - padding=same\n",
    "- Hidden Layer 3: Conv -> ReLU\n",
    "  - in_channels=8\n",
    "  - filters=16\n",
    "  - filter_size=2\n",
    "  - stride=1\n",
    "  - padding=same\n",
    "- Hidden Layer 4: MaxPool\n",
    "  - filter_size=4\n",
    "  - stride=4\n",
    "  - padding=same\n",
    "- Flatten Layer: Convert volume of size 16 x 63 x 63 (due to the \"floor\" operation the original size gets reduced to 63 even with _same_ padding) to vectors of size 63,504\n",
    "- Output Layer: Linear -> Softmax with 6 units\n",
    "\n",
    "To compute the padding needed for _same_ convolutions we can use the following formula (derived from the formula for the output height/width):\n",
    "\n",
    "$$p = \\frac{(h-1) \\cdot s - h + f}{2}$$\n",
    "\n",
    "where $h$ is the height (can also be substituted for the width), $s$ is the stride and $f$ is the filter size.\n",
    "\n",
    "_See: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            # Hidden Layer 1\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=4, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Hidden Layer 2\n",
    "            # We need to add a padding layer because the padding is larger than the kernel size which causes `MaxPool2d` to fail\n",
    "            nn.ZeroPad2d(padding=224),\n",
    "            nn.MaxPool2d(kernel_size=8, stride=8, padding=0),\n",
    "            # Hidden Layer 3\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Hidden Layer 4\n",
    "            # We need to add a padding layer because the padding is larger than the kernel size which causes `MaxPool2d` to fail\n",
    "            nn.ZeroPad2d(padding=96),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4, padding=0),\n",
    "            nn.Flatten(),\n",
    "            # Output layer\n",
    "            nn.Linear(in_features=63504, out_features=6),\n",
    "            # We don't add the softmax activation function here because it will be combined with the loss function\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We'll use Adam for training the model with the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "model = model.to(device)\n",
    "total_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "\n",
    "    for samples, targets in training:\n",
    "        optimizer.zero_grad()\n",
    "        samples = samples.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        output = model(samples)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Detach the loss to avoid saving any more computations on it\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        total_losses.append(np.mean(losses))\n",
    "        print(f'[{epoch}/{epochs}]\\tLoss: {total_losses[-1]}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model/model.pt')\n",
    "\n",
    "# Plot the losses per tens of epochs\n",
    "plt.plot(total_losses)\n",
    "plt.ylabel('Avg. Loss')\n",
    "plt.xlabel('Epochs (per tens)')\n",
    "plt.title('Avg. Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
