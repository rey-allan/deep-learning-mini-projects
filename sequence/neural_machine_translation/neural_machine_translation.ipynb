{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "\n",
    "Translating human-readable dates to standard machine-readable dates using attention mechanisms.\n",
    "\n",
    "_PyTorch implementation of the assignment of Course 5 of Coursera's Deep Learning Specialization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from babel.dates import format_date\n",
    "from faker import Faker\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "Faker.seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will create a custom dataset that will provide the following:\n",
    "\n",
    "- Each sample is a human-readable date, represented as an array of one-hot encoded indices where each index comes from a vocabulary padded to a length of $T_x=30$\n",
    "- Each corresponding target is a machine-readable date, represented as an array of indices where each index comes from a vocabulary of length $T_y=10$ (the form YYYY-MM-DD)\n",
    "- 10,000 training examples\n",
    "\n",
    "We will also generate the following dictionaries:\n",
    "\n",
    "- `human_to_idx`: mapping all characters used in the human-readable dates to indices including two special characters: `<UNK>` and `<PAD>`\n",
    "- `machine_to_idx`: mapping all characters used in machine-readable dates to indices\n",
    "- `idx_to_machine`: mapping from indices back to machine-readable characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake dates as training examples\n",
    "# Code taken from the Deep Learning Specialization assignment\n",
    "formats = ['short', 'medium', 'long', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'full', 'd MMM YYY', 'd MMMM YYY',\n",
    "           'dd MMM YYY', 'd MMM, YYY', 'd MMMM, YYY', 'dd, MMM YYY', 'd MM YY', 'd MMMM YYY', 'MMMM d YYY', 'MMMM d, YYY', 'dd.MM.YY']\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def create_date():\n",
    "    dt = fake.date_object()\n",
    "\n",
    "    try:\n",
    "        human_readable = format_date(dt, format=random.choice(formats),  locale='en_US')\n",
    "        human_readable = human_readable.lower()\n",
    "        human_readable = human_readable.replace(',', '')\n",
    "        machine_readable = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human_readable, machine_readable\n",
    "\n",
    "human_vocab = set()\n",
    "machine_vocab = set()\n",
    "dataset = []\n",
    "    \n",
    "\n",
    "for i in range(10000):\n",
    "    h, m = create_date()\n",
    "\n",
    "    if h is not None:\n",
    "        dataset.append((h, m))\n",
    "        human_vocab.update(tuple(h))\n",
    "        machine_vocab.update(tuple(m))\n",
    "\n",
    "    human_to_idx = dict(zip(sorted(human_vocab) + ['<UNK>', '<PAD>'], list(range(len(human_vocab) + 2))))\n",
    "    idx_to_machine = dict(enumerate(sorted(machine_vocab)))\n",
    "    machine_to_idx = {v:k for k, v in idx_to_machine.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some raw samples before any other preprocessing is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('june 23 2018', '2018-06-23'),\n",
       " ('sunday january 21 1996', '1996-01-21'),\n",
       " ('29 aug 2009', '2009-08-29'),\n",
       " ('saturday june 5 1982', '1982-06-05'),\n",
       " ('thursday november 8 1984', '1984-11-08'),\n",
       " ('friday may 22 1981', '1981-05-22'),\n",
       " ('friday march 18 1983', '1983-03-18'),\n",
       " ('saturday july 11 1981', '1981-07-11'),\n",
       " ('august 27 2015', '2015-08-27'),\n",
       " ('may 21 2016', '2016-05-21')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_indices(date, length, vocab):\n",
    "    # Taken from the Deep Learning Specialization assignment\n",
    "    date = date.lower().replace(',', '')\n",
    "\n",
    "    # Truncate\n",
    "    if len(date) > length:\n",
    "        date = date[:length]\n",
    "\n",
    "    # Convert to array of indices\n",
    "    date = list(map(lambda x: vocab.get(x, '<UNK>'), date))\n",
    "\n",
    "    # Pad\n",
    "    if len(date) < length:\n",
    "        date += [vocab['<PAD>']] * (length - len(date))\n",
    "\n",
    "    return date\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # We define a custom collate_fn so that we can do the following:\n",
    "    # - Convert human and machine dates into indices, padding/tuncating to Tx=30 and Ty=10, respectively\n",
    "    # - One-hot encode the human dates\n",
    "    human_dates, machine_dates = zip(*batch)\n",
    "\n",
    "    # Compute the original lengths which will be useful for packing the padded sequence\n",
    "    lengths = [len(d) for d in human_dates]\n",
    "    # Convert to indices, padding or truncating to Tx=30\n",
    "    human_dates = torch.tensor([to_indices(d, 30, human_to_idx) for d in human_dates])\n",
    "    # One-hot encode\n",
    "    human_dates = F.one_hot(human_dates, num_classes=len(human_to_idx)).float()\n",
    "\n",
    "    # Convert machine dates to indices\n",
    "    machine_dates = torch.tensor([to_indices(d, 10, machine_to_idx) for d in machine_dates]).long()\n",
    "\n",
    "    return human_dates, machine_dates, lengths\n",
    "\n",
    "\n",
    "class DatesDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X, self.y = zip(*dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the training set. We use the same batch size (100) as in the Deep Learning Specialization assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = DataLoader(DatesDataset(), batch_size=100, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use a **sequence-to-sequence** model with an attention mechanism as follows:\n",
    "\n",
    "- A pre-attention Bidirectional LSTM with 32 hidden units that takes in the one-hot encoded human-dates\n",
    "- A post-attention LSTM with 64 hidden units that takes in a context vector computed by an attention mechanism\n",
    "- An output layer, with softmax activation, over the vocabulary of the machine-readable dates\n",
    "\n",
    "Note that because our model uses a Bidirectional LSTM the whole input sequence $T_x$ is processed at once. As opposed to processing each timestep $t$ at a time.\n",
    "\n",
    "![](img/model.png)\n",
    "\n",
    "### Attention Mechanism\n",
    "\n",
    "The attention mechanism is computed as follows:\n",
    "\n",
    "- A fully-connected layer with 10 units and tanh activation that takes in all hidden states of the pre-attention Bidirectional LSTM and the previous hidden state of the post-attention LSTM\n",
    "- A second fully-connected layer with 1 unit and ReLU activation\n",
    "- A softmax activation over the previous output\n",
    "\n",
    "![](img/attn_mechanism.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        # Input shape (batch_size, 2 * 32 + 64) where\n",
    "        # - 2 * 32 comes from the activations of pre-attention Bidirectional LSTM\n",
    "        # - 64 comes from the previous hidden state of the post-attention LSTM\n",
    "        self.fc1 = nn.Sequential(nn.Linear(in_features=2 * 32 + 64, out_features=10), nn.Tanh())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(in_features=10, out_features=1), nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, a, s):\n",
    "        # Repeat the previous hidden state of the post-attention LSTM over all timesteps\n",
    "        # The shape will go from (batch_size, 64) to (batch_size, Tx=30, 64)\n",
    "        s = s.unsqueeze(1).repeat(1, 30, 1)\n",
    "        # Concatenate with the activations of the pre-attention Bidirectional LSTM\n",
    "        concatenated = torch.cat([a, s], axis=-1)\n",
    "        # Pass it through the two Fully-Connected layers and compute the weights using softmax over all timesteps\n",
    "        # The shape is (batch_size, Tx=30, 1) so we use dim=1 to apply softmax over the Tx dimension\n",
    "        weights = F.softmax(self.fc2(self.fc1(concatenated)), dim=1)\n",
    "        # Compute the context vector as a weight sum\n",
    "        # We permute the axes of the weights to go from (batch_size, seq_len, 1) to (batch_size, 1, seq_len) to correctly compute the dot product\n",
    "        # We also squeeze dim=1 of the context vector to go from (batch_size, 1, 64) to (batch_size, 64)\n",
    "        context = torch.matmul(weights.permute(0, 2, 1), a).squeeze(1)\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # The first LSTM layer expects sequences of size of the length of the human vocab\n",
    "        self.pre_lstm = nn.LSTM(input_size=len(human_to_idx), hidden_size=32, bidirectional=True, batch_first=True)\n",
    "        self.attn = Attention()\n",
    "        # The second LSTM layer takes in the context vector (a weight per each activation of the Bidirectional LSTM)\n",
    "        # We use `LSTMCell` since we will explicitly loop through each timestep of the output (Ty)\n",
    "        self.post_lstm = nn.LSTMCell(input_size=2 * 32, hidden_size=64)\n",
    "        # Output layer to convert to target space (length of the machine vocab)\n",
    "        self.out = nn.Linear(in_features=64, out_features=len(machine_to_idx))\n",
    "        # We don't define a softmax output layer explicitly because it's combined with the loss function\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        # Pack the padded sequence so that the layers ignore the padded values during backprop\n",
    "        # See: https://ryankresse.com/dealing-with-pad-tokens-in-sequence-models-loss-masking-and-pytorchs-packed-sequence/\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # Pass through Bidirectional LSTM to process the full sequence\n",
    "        hiddens, state = self.pre_lstm(packed)\n",
    "        # Since we passed in a packed sequence, we need to \"unpack\" it\n",
    "        # We need to make sure that the unpacking operation respects our initial desired max length of Tx=30 though!\n",
    "        # See: https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "        a, _= torch.nn.utils.rnn.pad_packed_sequence(hiddens, batch_first=True, padding_value=human_to_idx['<PAD>'], total_length=30)\n",
    "        # Initialize the hidden and cell states of the post-attention LSTM with shape (batch_size, hidden_size=64)\n",
    "        s = torch.zeros(input.shape[0], 64).float().to(input.device)\n",
    "        c = torch.zeros(input.shape[0], 64).float().to(input.device)\n",
    "        # Holds all the outputs for all timesteps of the output sequence (Ty) of shape (batch_size, Ty=10, len(machine_vocab))\n",
    "        outputs = torch.zeros(input.shape[0], 10, len(machine_to_idx)).to(input.device)\n",
    "\n",
    "        # Generate each output one by one since the attention mechanism requires the previous hidden state from the post-attention LSTM at each step\n",
    "        for i in range(10):\n",
    "            # Pass through attention mechanism to generate the context vector\n",
    "            context = self.attn(a, s)\n",
    "            # Pass through post-attention LSTM\n",
    "            s, c = self.post_lstm(context, (s, c))\n",
    "            # Convert to target space\n",
    "            output = self.out(s)\n",
    "            outputs[:, i, :] = output\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (pre_lstm): LSTM(37, 32, batch_first=True, bidirectional=True)\n",
      "  (attn): Attention(\n",
      "    (fc1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=10, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (fc2): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (post_lstm): LSTMCell(64, 64)\n",
      "  (out): Linear(in_features=64, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We'll use Adam for training the model with the cross-entropy loss. We'll use the same learning rate as in the Deep Learning Specialization assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/35]\tLoss: 2.1164774894714355\n",
      "[1/35]\tLoss: 2.0184097290039062\n",
      "[2/35]\tLoss: 1.4495065212249756\n",
      "[3/35]\tLoss: 0.8534033894538879\n",
      "[4/35]\tLoss: 0.7653688192367554\n",
      "[5/35]\tLoss: 0.5815529823303223\n",
      "[6/35]\tLoss: 0.442037969827652\n",
      "[7/35]\tLoss: 0.30376631021499634\n",
      "[8/35]\tLoss: 0.18202467262744904\n",
      "[9/35]\tLoss: 0.10328581929206848\n",
      "[10/35]\tLoss: 0.056844159960746765\n",
      "[11/35]\tLoss: 0.032530777156353\n",
      "[12/35]\tLoss: 0.02193582057952881\n",
      "[13/35]\tLoss: 0.016952818259596825\n",
      "[14/35]\tLoss: 0.013270527124404907\n",
      "[15/35]\tLoss: 0.010394573211669922\n",
      "[16/35]\tLoss: 0.008912596851587296\n",
      "[17/35]\tLoss: 0.007201767060905695\n",
      "[18/35]\tLoss: 0.005956578999757767\n",
      "[19/35]\tLoss: 0.00629280973225832\n",
      "[20/35]\tLoss: 0.0047896746546030045\n",
      "[21/35]\tLoss: 0.004013095051050186\n",
      "[22/35]\tLoss: 0.004252012353390455\n",
      "[23/35]\tLoss: 0.004102514591068029\n",
      "[24/35]\tLoss: 0.003191363764926791\n",
      "[25/35]\tLoss: 0.002497264416888356\n",
      "[26/35]\tLoss: 0.002083725295960903\n",
      "[27/35]\tLoss: 0.002214329782873392\n",
      "[28/35]\tLoss: 0.0018872880609706044\n",
      "[29/35]\tLoss: 0.0019836656283587217\n",
      "[30/35]\tLoss: 0.001940980670042336\n",
      "[31/35]\tLoss: 0.0017568778712302446\n",
      "[32/35]\tLoss: 0.01889551430940628\n",
      "[33/35]\tLoss: 0.01366605143994093\n",
      "[34/35]\tLoss: 0.002621154533699155\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main training loop\n",
    "model = model.to(device)\n",
    "total_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "\n",
    "    for samples, targets, lengths in training:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        samples = samples.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        output = model(samples, lengths)\n",
    "\n",
    "        # Reshape the outputs and targets to (batch_size * seq_len, len(machine_vocab)) so the loss can be computed\n",
    "        output = output.view(-1, len(machine_to_idx))\n",
    "        targets = targets.flatten()\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Detach the loss to avoid saving any more computations on it\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    total_losses.append(np.mean(losses))\n",
    "    print(f'[{epoch}/{epochs}]\\tLoss: {total_losses[-1]}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model/model.pt')\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(np.squeeze(total_losses))\n",
    "plt.ylabel('Avg. Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Avg. Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Now that we have trained our model, we can try it with the same examples from the Deep Learning Specialization assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 3 May 1979\n",
      "Machine: 1979-05-03\n",
      "\n",
      "Human: 5 April 09\n",
      "Machine: 2009-04-05\n",
      "\n",
      "Human: 21th of August 2016\n",
      "Machine: 2016-08-02\n",
      "\n",
      "Human: Tue 10 Jul 2007\n",
      "Machine: 2007-07-10\n",
      "\n",
      "Human: Saturday May 9 2018\n",
      "Machine: 2018-05-09\n",
      "\n",
      "Human: March 3 2001\n",
      "Machine: 2001-03-03\n",
      "\n",
      "Human: March 3rd 2001\n",
      "Machine: 2001-03-03\n",
      "\n",
      "Human: 1 March 2001\n",
      "Machine: 2001-03-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load('model/model.pt'))\n",
    "# Always set the mode to `eval` for inference\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "examples = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001',\n",
    "            '1 March 2001']\n",
    "\n",
    "for example in examples:\n",
    "    # Preprocess like we did for the training samples\n",
    "    lengths = [len(example)]\n",
    "    human = torch.tensor(to_indices(example, 30, human_to_idx))\n",
    "    human = F.one_hot(human, num_classes=len(human_to_idx)).float()\n",
    "    # Add the batch_size=1 dimension\n",
    "    human = human.unsqueeze(0)\n",
    "\n",
    "    # Predict and grab the most likely index for each timestep of the output sequence\n",
    "    preds = model(human.to(device), lengths).squeeze(0)\n",
    "    preds = F.softmax(preds, dim=-1)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "    # Convert back to a machine-readable date\n",
    "    machine = [idx_to_machine[int(i)] for i in preds]\n",
    "\n",
    "    print(f'Human: {example}')\n",
    "    print(f'Machine: {\"\".join(machine)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a small amount of epochs, the model is able to learn quite well how to translate dates from very different human-readable formats!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
