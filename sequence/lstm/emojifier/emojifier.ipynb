{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojifier\n",
    "\n",
    "Selecting the best emoji for a sentence using LSTM's and word embeddings.\n",
    "\n",
    "_PyTorch implementation of the assignment of Course 5 of Coursera's Deep Learning Specialization_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will create a custom dataset that will provide the following:\n",
    "\n",
    "- Each sample is a sentence, represented as an array of word indices where each index comes from a vocabulary provided by GloVe vectors\n",
    "- Each corresponding target is the index of the emoji that best matches the sentence\n",
    "- 132 training examples\n",
    "- 55 testing examples\n",
    "\n",
    "The following image shows an example of what the dataset looks like.\n",
    "\n",
    "![](img/emoji_dataset.png)\n",
    "\n",
    "### GloVe Vectors\n",
    "\n",
    "We will use pre-trained GloVe vectors that can be downloaded from the [official site](https://nlp.stanford.edu/projects/glove/). Specifically, we will use the `glove.6B.50d.txt` file (6B tokens and vectors of dimension 50) from the `glove.6b.zip` file. We will define two dictionaries to map a word to its GloVe index, and an index to its GloVe vectors. As part of this dictionaries we will add an extra entry for the `<PAD>` value used for padding the sentences to be of equal length.\n",
    "\n",
    "_Note: See this [blog post](https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76) for an explanation on how to use GloVe vectors in Pytorch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "vectors = {}\n",
    "\n",
    "with open('data/glove.6B.50d.txt', 'r') as f:\n",
    "    words = set()\n",
    "    vectors = {}\n",
    "\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.strip().split()\n",
    "        word = line[0]\n",
    "        vectors[i] = np.array(line[1:], dtype=np.float64)\n",
    "        word_to_ix[word] = i\n",
    "\n",
    "# Add the padding value\n",
    "word_to_ix['<PAD>'] = len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # We define a custom collate_fn so that we can pad the sentences to have the same length\n",
    "    # See: https://ryankresse.com/dealing-with-pad-tokens-in-sequence-models-loss-masking-and-pytorchs-packed-sequence/\n",
    "    sentences, labels = zip(*batch)\n",
    "\n",
    "    # Compute the original lengths which will be useful for packing the padded sequence\n",
    "    lengths = [len(s) for s in sentences]\n",
    "    # Pad sentences into batch of shape (batch_size, max_len)\n",
    "    sentences = nn.utils.rnn.pad_sequence(sentences, batch_first=True, padding_value=word_to_ix['<PAD>'])\n",
    "    \n",
    "    # Merge labels into batch of shape (batch_size,)\n",
    "    labels = torch.stack(labels, 0)\n",
    "   \n",
    "    return sentences, labels, lengths\n",
    "\n",
    "\n",
    "class EmojiDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        dataset = pd.read_csv(f'data/{mode}_emoji.csv', header=None)\n",
    "        self.X = [torch.tensor([word_to_ix[w] for w in s.strip().lower().split()]) for s in dataset[0].values]\n",
    "        self.y = dataset[1].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        X = self.X[idx]\n",
    "        y = torch.tensor(self.y[idx]).long()\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For display purposes, we define a dictionary of labels to the actual emoji symbols. This is the same as the one used in the Deep Learning Specialization assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_emoji = {\n",
    "    '0': '\\u2764\\uFE0F',  # :heart: prints a black instead of red heart depending on the font\n",
    "    '1': ':baseball:',\n",
    "    '2': ':smile:',\n",
    "    '3': ':disappointed:',\n",
    "    '4': ':fork_and_knife:'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = DataLoader(EmojiDataset(mode='train'), batch_size=32, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "testing = DataLoader(EmojiDataset(mode='test'), batch_size=32, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use an LSTM with the following structure:\n",
    "\n",
    "- An embedding layer that converts the indices of a sentence into GloVe vectors of dimension 50\n",
    "- A first LSTM layer with 128 units followed by a Dropout layer\n",
    "- A second LSTM layer with 128 units\n",
    "- One single output, at the last timestep, that follows the LSTM cell with a Dropout layer and a softmax output function\n",
    "\n",
    "This structure means our model is of type **sequence-to-one**; producing one single output after having processed the input sequence $T_x$.\n",
    "\n",
    "![](img/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding layer generated from the pre-trained GloVe vectors\n",
    "# See: https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76\n",
    "class GloVeEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GloVeEmbedding, self).__init__()\n",
    "\n",
    "        # Generate the matrix of weights as a lookup table from word indices to the GloVe vectors\n",
    "        weights = np.zeros((len(word_to_ix), 50))\n",
    "        for _, idx in word_to_ix.items():\n",
    "            # If the index is not in GloVe (e.g. the padding value) we use all zeros\n",
    "            weights[idx, :] = vectors[idx] if idx in vectors else np.zeros(50)\n",
    "\n",
    "        # Instantiate the pre-trained embedding\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(weights).float())\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.embedding(input)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.embedding = GloVeEmbedding()\n",
    "        # The first LSTM layer expects sequences of size `embedding_size=50`\n",
    "        self.lstm = nn.LSTM(input_size=50, hidden_size=128, num_layers=2, dropout=0.5, batch_first=True)\n",
    "        # This dropout will be used for the output since PyTorch doesn't introduce a dropout layer after the last LSTM layer\n",
    "        # See: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # Output layer to convert to target space (5 different emojis)\n",
    "        self.out = nn.Linear(in_features=128, out_features=5)\n",
    "        # We don't define a softmax output layer explicitly because it's combined with the loss function\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        # Embed\n",
    "        embeddings = self.embedding(input)\n",
    "        # Pack the padded sequence so that the layers ignore the padded values during backprop\n",
    "        # See: https://ryankresse.com/dealing-with-pad-tokens-in-sequence-models-loss-masking-and-pytorchs-packed-sequence/\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
    "        # Pass through LSTM\n",
    "        # The activations are not passed in so that they are initialized to zero; we don't need to pass the previous activations\n",
    "        # because we are training in batches which allows the model to learn enough before the state is re-initialized;\n",
    "        # if we were training using a single example then we would need to pass the previous state (like we did in the dinosaur name\n",
    "        # generation project) because with one example the model can't learn enough for the state to be reset every time\n",
    "        hiddens, state = self.lstm(packed)\n",
    "        # Apply dropout to the output at timestep T of the last layer\n",
    "        h_T, _ = state\n",
    "        h_T = self.dropout(h_T[-1, :, :])\n",
    "        # Convert to target space\n",
    "        output = self.out(h_T)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): GloVeEmbedding(\n",
      "    (embedding): Embedding(400001, 50)\n",
      "  )\n",
      "  (lstm): LSTM(50, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (out): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We'll use Adam for training the model with the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/40]\tLoss: 1.5671966075897217\n",
      "[1/40]\tLoss: 1.4753220081329346\n",
      "[2/40]\tLoss: 1.1786296367645264\n",
      "[3/40]\tLoss: 1.1316914558410645\n",
      "[4/40]\tLoss: 1.1219285726547241\n",
      "[5/40]\tLoss: 0.8289729356765747\n",
      "[6/40]\tLoss: 0.634110689163208\n",
      "[7/40]\tLoss: 0.560330867767334\n",
      "[8/40]\tLoss: 0.5661546587944031\n",
      "[9/40]\tLoss: 0.6716629862785339\n",
      "[10/40]\tLoss: 0.3340730369091034\n",
      "[11/40]\tLoss: 0.30723971128463745\n",
      "[12/40]\tLoss: 0.2479889839887619\n",
      "[13/40]\tLoss: 0.16478204727172852\n",
      "[14/40]\tLoss: 0.14478492736816406\n",
      "[15/40]\tLoss: 0.1768120974302292\n",
      "[16/40]\tLoss: 0.13828134536743164\n",
      "[17/40]\tLoss: 0.11401889473199844\n",
      "[18/40]\tLoss: 0.10209661722183228\n",
      "[19/40]\tLoss: 0.08762462437152863\n",
      "[20/40]\tLoss: 0.032750204205513\n",
      "[21/40]\tLoss: 0.06966733187437057\n",
      "[22/40]\tLoss: 0.05570991709828377\n",
      "[23/40]\tLoss: 0.03655354306101799\n",
      "[24/40]\tLoss: 0.023768045008182526\n",
      "[25/40]\tLoss: 0.015164835378527641\n",
      "[26/40]\tLoss: 0.01278142910450697\n",
      "[27/40]\tLoss: 0.0065477630123496056\n",
      "[28/40]\tLoss: 0.01093561016023159\n",
      "[29/40]\tLoss: 0.016081945970654488\n",
      "[30/40]\tLoss: 0.005041820462793112\n",
      "[31/40]\tLoss: 0.01315411925315857\n",
      "[32/40]\tLoss: 0.004055744502693415\n",
      "[33/40]\tLoss: 0.004411798901855946\n",
      "[34/40]\tLoss: 0.009508808143436909\n",
      "[35/40]\tLoss: 0.0016641013789922\n",
      "[36/40]\tLoss: 0.0013870381517335773\n",
      "[37/40]\tLoss: 0.00965103879570961\n",
      "[38/40]\tLoss: 0.003894637105986476\n",
      "[39/40]\tLoss: 0.021863501518964767\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main training loop\n",
    "model = model.to(device)\n",
    "total_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "\n",
    "    for samples, targets, lengths in training:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        samples = samples.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        output = model(samples, lengths)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Detach the loss to avoid saving any more computations on it\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    total_losses.append(np.mean(losses))\n",
    "    print(f'[{epoch}/{epochs}]\\tLoss: {total_losses[-1]}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model/model.pt')\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(np.squeeze(total_losses))\n",
    "plt.ylabel('Avg. Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title('Avg. Loss per Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Now that we have trained our model, we can evaluate it against the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8854166666666667\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load('model/model.pt'))\n",
    "# Always set the mode to `eval` for inference\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Main inference loop\n",
    "with torch.no_grad():\n",
    "    for samples, targets, lengths in testing:\n",
    "        output = model(samples.to(device), lengths)\n",
    "\n",
    "        # Compute the probabilities of each emoji label via softmax\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        # Use the label of the highest probability\n",
    "        preds = np.argmax(probs.detach().cpu().numpy(), axis=-1)\n",
    "\n",
    "        # Remove extra dimension, i.e. flatten as vector\n",
    "        targets = np.squeeze(targets.detach().cpu().numpy())\n",
    "\n",
    "        # Evaluate using accuracy\n",
    "        accuracies.append(np.mean(preds == targets))\n",
    "\n",
    "print(f'Accuracy = {np.mean(accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try it with our own example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great news ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "sentence = 'great news'\n",
    "input = torch.tensor([word_to_ix[w] for w in sentence.strip().lower().split()])\n",
    "# Add `batch_size=1` dimension\n",
    "input = input.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input.to(device), [len(sentence)])\n",
    "    probs = F.softmax(output, dim=-1)\n",
    "    label = np.argmax(probs.detach().cpu().numpy())\n",
    "\n",
    "print(f'{sentence} {emoji.emojize(label_to_emoji[str(label)], use_aliases=True)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
